# CuresDev Personal Identifiable Information (PII) Tokenizer Specification

In this document we describe the specification of the CureDev PII tokenizer version 1.0.

## Input fields

We define a set of input fields that are used to generate the tokens.

All input fields are strings, some of them with a specific format that they need to follow.

Name:

| input field | required | format |
| ----------- | -------- | ------ |
| first_name  | required | string |
| last_name   | required | string |
| middle_name | optional | string |
| former_name | optional | string |

Birth:

| input field   | required | format        |
| ------------- | -------- | ------------- |
| date_of_birth | required | ISO 8601 date |
| sex_at_birth  | optional | "M" or "F"    |

Location:

| input field            | required | format                 |
| ---------------------- | -------- | ---------------------- |
| city_at_birth          | optional | string                 |
| address_at_bith        | optional | string                 |
| zip_code_at_birth      | optional | string                 |
| abbr_zip_code_at_birth | optional | string                 |
| state_at_birth         | optional | string                 |
| country_at_birth       | optional | 2 or 3 letter ISO code |

Parents:

| input field        | required | format           |
| ------------------ | -------- | ---------------- |
| parent1_first_name | optional | string           |
| parent1_last_name  | optional | string           |
| parent1_email      | optional | email (RFC 3696) |
| parent2_first_name | optional | string           |
| parent2_last_name  | optional | string           |
| parent2_email      | optional | email (RFC 3696) |

## Derived fields

The full name of both the patient and their parents are constructed by concatenating their first name, middle name and last name (if present).

| field             | content                                |
| ----------------- | -------------------------------------- |
| full_name         | first_name + middle_name + last_name   |
| parent1_full_name | parent1_first_name + parent1_last_name |
| parent2_full_name | parent2_first_name + parent2_last_name |


# Normalization

We perform a normalization process in order to prevent the same string from being represented in very different ways.

For fields that have a specific format, such as `date_of_birth`, we perform a format validation and normalization.
The same is applied to `parent1_email` and `parent2_email` fields, which are validated against the [RFC 3696](https://tools.ietf.org/html/rfc3696) specification.
`sex_at_birth` is validated against the values "M" and "F

All free-form strings are normalized with the following preprocessing steps:

1. Convert all letters to lowercase
2. Replace all accented characters with their unaccented version.
3. Remove whitespace at the beggining and the end of the string.
4. Join all contiguous whitespace inside the string into a single space character.

After these steps, we have two types of normalization:

* **keep_letters_and_numbers**: in which we remove all characters that are not letters or numbers.
* **keep_letters**: in which we remove all characters that are not letters.

# Expansion

For fields that consist of a free-form string, we perform an expansion process that generates a set of bigrams from the string.
This expansions allows the token to capture the similarity between strings that are not exactly the same.
The details of the expansion process are described in [Appendix A](#appendix-a-methods).

In addition to bigrams, the `first_name` and `last_name` fields are also transformed by the [Soundex](#appendix-a-methods) algorithm.

# Tokenization

Each token is generated by inserting the expanded strings into a Bloom filter of **1024 bits** with a dynamic number of hash functions.
We choose the number of hash functions dynamically, based on the number of bigrams that are inserted into the filter.
The goal is to insert ln(2)*1024 ones, which results in a Bloom filter with approximately half of the bits set to 1.

# Differential privacy

Each Bloom filter is perturbed with a differential privacy mechanism that adds noise to the token.
Depending on the field, we introduce different amounts of noise.
For fields with lower cardinality, we add more noise in order to prevent a dictionary attack with which the tokenized value can be identified.
In [Appendix A](#appendix-a-methods) we describe the estimations we made for the cardinality of each field.


# Table of tokens


| token                        | input field                            | normalization            | expansion | differential privacy |
| ---------------------------- | -------------------------------------- | ------------------------ | --------- | -------------------- |
| first_name_token             | first_name*                            | keep_letters             | bigrams   | epsilon=3            |
| first_name_soundex_token     | first_name*                            | keep_letters             | soundex   | epsilon=3            |
| last_name_token              | last_name*                             | keep_letters             | bigrams   | epsilon=3            |
| last_name_soundex_token      | last_name*                             | keep_letters             | soundex   | epsilon=3            |
| middle_name_token            | middle_name                            | keep_letters             | bigrams   | epsilon=3            |
| full_name_token              | first_name* + middle_name + last_name* | keep_letters             | bigrams   | epsilon=3            |
| date_of_birth_token          | date_of_birth*                         | ISO 8601 date            |           | epsilon=0.4          |
| former_name_token            | former_name                            | keep_letters             | bigrams   | epsilon=3            |
| sex_at_birth_token           | sex_at_birth                           | "M" or "F"               |           | epsilong=0.2         |
| city_at_birth_token          | city_at_birth                          | keep_letters             | bigrams   | epsilon=3            |
| address_at_bith_token        | address_at_bith                        | keep_letters_and_numbers | bigrams   | epsilon=3            |
| zip_code_at_birth_token      | zip_code_at_birth                      | keep_letters_and_numbers |           | epsilon=0.3          |
| abbr_zip_code_at_birth_token | abbr_zip_code_at_birth                 | keep_letters_and_numbers |           | epsilon=0.4          |
| state_at_birth_token         | state_at_birth                         | keep_letters             |           | epsilon=0.2          |
| country_at_birth_token       | country_at_birth                       | 2 or 3 letter ISO code   |           | epsilon=0.2          |
| parent1_first_name_token     | parent1_first_name                     | keep_letters             | bigrams   | epsilon=3            |
| parent1_last_name_token      | parent1_last_name                      | keep_letters             | bigrams   | epsilon=3            |
| parent1_full_name_token      | parent1_first_name + parent1_last_name | keep_letters             | bigrams   | epsilon=3            |
| parent1_email_token          | parent1_email                          | email (RFC 3696)         | bigrams   | epsilon=3            |
| parent2_first_name_token     | parent2_first_name                     | keep_letters             | bigrams   | epsilon=3            |
| parent2_last_name_token      | parent2_last_name                      | keep_letters             | bigrams   | epsilon=3            |
| parent2_full_name_token      | parent2_first_name + parent2_last_name | keep_letters             | bigrams   | epsilon=3            |
| parent2_email_token          | parent2_email                          | email (RFC 3696)         | bigrams   | epsilon=3            |

* = Required fields

# Appendix A: methods

## Bigrams expansion

The bigrams of a string are generated by taking all the pairs of consecutive characters in the string.

```
bigrams("abc") = ["ab", "bc"]
```

In the edge case of strings of zero or one character, we keep that string as the only bigram:

```
bigrams("") = [""]
bigrams("a") = ["a"]
```

In our implementation of the bigrams method, we also add a suffix for each bigram which indicates how many times that bigram appears in the string. For example:


```
bigrams("barbara) = ["ba:1", "ar:1", "rb:1", "ba:2", "ar:2", "ra:1"]
```


## Soundex

Explanation of the Soundex method used.

## Cardinality estimation

Estimation of the cardinality of the following fields:

| Type of field        | Cardinality |
| -------------------- | ----------- |
| Sex                  | 2           |
| Date                 | 36500       |
| Abbreviated zip code | ??          |
| Zip code             | ??          |
| Country              | 200         |
| State                | 20          |

# Appendix B: privacy guarantees

Explanation on how we choose the epsilon values for each field.